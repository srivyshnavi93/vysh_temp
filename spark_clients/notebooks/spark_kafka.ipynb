{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3ccfc-0040-4a10-8e0d-d6dae4f2e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init() \n",
    "\n",
    "import pyspark\n",
    "from delta import *\n",
    "from delta import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f88ab-e54b-4768-ad79-3f3f84fcdc8e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"spark_kafka\").config(\"spark.sql.streaming.metricsEnabled\", \"true\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424076d-b3dd-46eb-b7cc-1d588b02ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show databases\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35903d-9cff-4290-841e-1b65bc7c249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables in test_db\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536430de-4cea-4494-8e55-80ecc1511453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"drop table test_db.spark_kafka\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2f08f-a3e8-4f43-abef-e9c2ab9e05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"create database if not exists bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951dc39-dce6-4390-9bcb-5f25f2f6b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic = \"test-topic-1\"\n",
    "topic = \"weather_test_v1\"\n",
    "maxOffsetsPerTrigger = 100\n",
    "\n",
    "df = spark\\\n",
    "    .readStream\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka-broker:9092\")\\\n",
    "    .option(\"subscribe\", topic)\\\n",
    "    .option(\"maxOffsetsPerTrigger\", maxOffsetsPerTrigger) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ddaf0b-134c-4907-88da-2ded7495d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.selectExpr(\"cast(value as string) as payload\", \"*\").limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1311e5-86ec-4e68-841a-ec3fe3f1afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_interval = \"60 seconds\"\n",
    "queryName = \"weather_test_v1\"\n",
    "tableName = \"weather_test_v1\"\n",
    "\n",
    "df\\\n",
    ".selectExpr(\"key\", \"topic\", \"partition\", \"offset\", \"timestamp\", \"timestampType\", \"cast(value as string) as payload\") \\\n",
    ".writeStream \\\n",
    ".trigger(processingTime = trigger_interval) \\\n",
    ".queryName(queryName) \\\n",
    ".format(\"delta\") \\\n",
    ".outputMode(\"append\") \\\n",
    ".option(\"checkpointLocation\", f\"/opt/spark/work-dir/odp_intra_storage/spark/datalake/bronze.db/{tableName}/_ckpt\") \\\n",
    ".toTable(f\"bronze.{tableName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc722f-f1c8-4e12-9a6f-4ddf9b1fc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select payload from bronze.weather_test_v1 limit 2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1535ee1-4065-4b50-91d2-617b51ae6987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe7576-1a61-41d5-b357-73c65b31c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select current_timestamp - INTERVAL 10 minutes\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f85bc-d100-4476-a073-6c6f8f5e5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"OPTIMIZE test_db.spark_kafka\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654c705-0e85-4bf8-8e89-b9e6599b8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"set spark.databricks.delta.retentionDurationCheck.enabled = false\")\n",
    "spark.sql(\"SET spark.databricks.delta.vacuum.parallelDelete.enabled = true\")\n",
    "spark.sql(\"VACUUM test_db.spark_kafka RETAIN 0 HOURS\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2be5f-7f47-4742-bdbd-8ddfdc1c957f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439bb8fc-b2f4-4d0f-91c2-a9fb0ebdd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_expr = [\"get_json_object(payload, '$.data.location') as location\",\n",
    " \"get_json_object(payload, '$.data.time') as time\",\n",
    " \"get_json_object(payload, '$.data.info') as info\",\n",
    " \"get_json_object(payload, '$.data.temperature') as temperature\",\n",
    " \"get_json_object(payload, '$.data.precipitation') as precipitation\",\n",
    " \"get_json_object(payload, '$.data.humidiy') as humidity\",\n",
    " \"get_json_object(payload, '$.data.wind') as wind\",\n",
    " \"topic as kafka_topic\",\n",
    " \"partition as kafka_partition\",\n",
    " \"offset as kafka_offset\",\n",
    " \"cast(timestamp as timestamp) as kafka_timestamp\",\n",
    " \"cast(timestamp as date) as kafka_date\", \n",
    " \"current_timestamp as load_time\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1be038-5012-4330-8245-250fe0c2be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"bronze.weather_test_v1\").selectExpr(select_expr).orderBy(col(\"kafka_offset\").desc()).limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e466aaf-5823-4098-aa6e-ce68e20dee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"create database if not exists silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71de2e-edbd-47b8-8343-748173087c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"drop table if exists silver.weather_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ba390-590a-4015-a001-24518d57cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table silver.weather_test \n",
    "(\n",
    "location string,\n",
    "time string,\n",
    "info string,\n",
    "temperature string,\n",
    "precipitation string,\n",
    "humidity string,\n",
    "wind string,\n",
    "kafka_topic string,\n",
    "kafka_partition int,\n",
    "kafka_offset bigint,\n",
    "kafka_timestamp timestamp,\n",
    "kafka_date date,\n",
    "load_time timestamp\n",
    ")\n",
    "using delta\n",
    ";\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1de7e-e80f-4804-8490-4be6fbab3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_interval = \"60 seconds\"\n",
    "queryName = \"silver_weather_test\"\n",
    "tableName = \"weather_test\"\n",
    "\n",
    "spark.readStream \\\n",
    ".format(\"delta\") \\\n",
    ".table(\"bronze.weather_test_v1\") \\\n",
    ".selectExpr(select_expr) \\\n",
    ".writeStream \\\n",
    ".trigger(processingTime = trigger_interval) \\\n",
    ".queryName(queryName) \\\n",
    ".format(\"delta\") \\\n",
    ".outputMode(\"append\") \\\n",
    ".option(\"checkpointLocation\", f\"/opt/spark/work-dir/odp_intra_storage/spark/datalake/silver.db/{tableName}/_ckpt\") \\\n",
    ".toTable(f\"silver.{tableName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d0ceb-0657-4ce2-ad01-b7d76afd4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "kafka_timestamp\n",
    ", max(temperature) as temperature\n",
    ", max(cast(replace(precipitation, '%', '') as int)) as precipitation\n",
    ", max(cast(replace(humidity, '%', '') as int)) as humidity\n",
    ", max(cast(replace(wind, ' mph', '') as int)) as wind\n",
    "from silver.weather_test \n",
    "where 1=1\n",
    "and location = 'Naperville'\n",
    "group by 1\n",
    ";\n",
    "\"\"\").limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcc3f4-687b-4aac-a10a-0169ac9ab08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (default, Apr 24 2020, 18:51:23) \n[Clang 11.0.3 (clang-1103.0.32.62)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
